{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Inception\n\n![Structure of the Inception block. ](http://www.d2l.ai/_images/inception.svg)","metadata":{"slideshow":{"slide_type":"slide"}}},{"cell_type":"code","source":"import mxnet as mx\nimport sys\nimport time\nfrom mxnet import autograd, gluon, init, nd\nfrom mxnet.gluon import loss as gloss, nn\n","metadata":{"execution":{"iopub.status.busy":"2022-07-01T06:39:14.087125Z","iopub.execute_input":"2022-07-01T06:39:14.087664Z","iopub.status.idle":"2022-07-01T06:39:14.097593Z","shell.execute_reply.started":"2022-07-01T06:39:14.087615Z","shell.execute_reply":"2022-07-01T06:39:14.095857Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class Inception(nn.Block):\n    # c1 - c4 are the number of output channels for each layer in the path.\n    def __init__(self, c1, c2, c3, c4, **kwargs):\n        super(Inception, self).__init__(**kwargs)\n        # Path 1 is a single 1 x 1 convolutional layer.\n        self.p1_1 = nn.Conv2D(c1, kernel_size=1, activation='relu')\n        # Path 2 is a 1 x 1 convolutional layer followed by a 3 x 3 convolutional layer.\n        self.p2_1 = nn.Conv2D(c2[0], kernel_size=1, activation='relu')\n        self.p2_2 = nn.Conv2D(c2[1], kernel_size=3, padding=1, activation='relu')\n        # Path 3 is a 1 x 1 convolutional layer followed by a 5 x 5 convolutional layer.\n        self.p3_1 = nn.Conv2D(c3[0], kernel_size=1, activation='relu')\n        self.p3_2 = nn.Conv2D(c3[1], kernel_size=5, padding=2, activation='relu')\n        # Path 4 is a 3 x 3 maximum pooling layer followed by a 1 x 1 convolutional layer.\n        self.p4_1 = nn.MaxPool2D(pool_size=3, strides=1, padding=1)\n        self.p4_2 = nn.Conv2D(c4, kernel_size=1, activation='relu')\n\n    def forward(self, x):\n        p1 = self.p1_1(x)\n        p2 = self.p2_2(self.p2_1(x))\n        p3 = self.p3_2(self.p3_1(x))\n        p4 = self.p4_2(self.p4_1(x))\n        # Concatenate the outputs on the channel dimension.\n        return nd.concat(p1, p2, p3, p4, dim=1)","metadata":{"attributes":{"classes":[],"id":"","n":"1"},"slideshow":{"slide_type":"slide"},"execution":{"iopub.status.busy":"2022-07-01T06:39:14.102709Z","iopub.execute_input":"2022-07-01T06:39:14.103745Z","iopub.status.idle":"2022-07-01T06:39:14.127453Z","shell.execute_reply.started":"2022-07-01T06:39:14.103705Z","shell.execute_reply":"2022-07-01T06:39:14.126324Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"### Inception Model - Stage 1","metadata":{"slideshow":{"slide_type":"slide"}}},{"cell_type":"code","source":"b1 = nn.Sequential()\nb1.add(nn.Conv2D(64, kernel_size=7, strides=2, padding=3, activation='relu'),\n       nn.MaxPool2D(pool_size=3, strides=2, padding=1))","metadata":{"attributes":{"classes":[],"id":"","n":"2"},"execution":{"iopub.status.busy":"2022-07-01T06:39:14.133129Z","iopub.execute_input":"2022-07-01T06:39:14.134500Z","iopub.status.idle":"2022-07-01T06:39:14.145540Z","shell.execute_reply.started":"2022-07-01T06:39:14.134461Z","shell.execute_reply":"2022-07-01T06:39:14.144114Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"### Inception Model - Stage 2","metadata":{}},{"cell_type":"code","source":"b2 = nn.Sequential()\nb2.add(nn.Conv2D(64, kernel_size=1),\n       nn.Conv2D(192, kernel_size=3, padding=1),\n       nn.MaxPool2D(pool_size=3, strides=2, padding=1))","metadata":{"attributes":{"classes":[],"id":"","n":"3"},"execution":{"iopub.status.busy":"2022-07-01T06:39:14.152627Z","iopub.execute_input":"2022-07-01T06:39:14.154970Z","iopub.status.idle":"2022-07-01T06:39:14.164084Z","shell.execute_reply.started":"2022-07-01T06:39:14.154932Z","shell.execute_reply":"2022-07-01T06:39:14.162984Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"### Inception Model - Stage 3","metadata":{"slideshow":{"slide_type":"slide"}}},{"cell_type":"code","source":"b3 = nn.Sequential()\nb3.add(Inception(64, (96, 128), (16, 32), 32),\n       Inception(128, (128, 192), (32, 96), 64),\n       nn.MaxPool2D(pool_size=3, strides=2, padding=1))","metadata":{"attributes":{"classes":[],"id":"","n":"4"},"execution":{"iopub.status.busy":"2022-07-01T06:39:14.169359Z","iopub.execute_input":"2022-07-01T06:39:14.171852Z","iopub.status.idle":"2022-07-01T06:39:14.187428Z","shell.execute_reply.started":"2022-07-01T06:39:14.171810Z","shell.execute_reply":"2022-07-01T06:39:14.186256Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"### Inception Model - Stage 4\n\nWe use a total of 512 channels (128 + 256 + 64 + 64) ","metadata":{}},{"cell_type":"code","source":"b4 = nn.Sequential()\nb4.add(Inception(192, (96, 208), (16, 48), 64),\n       Inception(160, (112, 224), (24, 64), 64),\n       Inception(128, (128, 256), (24, 64), 64),\n       Inception(112, (144, 288), (32, 64), 64),\n       Inception(256, (160, 320), (32, 128), 128),\n       nn.MaxPool2D(pool_size=3, strides=2, padding=1))","metadata":{"attributes":{"classes":[],"id":"","n":"5"},"execution":{"iopub.status.busy":"2022-07-01T06:39:14.191840Z","iopub.execute_input":"2022-07-01T06:39:14.194169Z","iopub.status.idle":"2022-07-01T06:39:14.222465Z","shell.execute_reply.started":"2022-07-01T06:39:14.194132Z","shell.execute_reply":"2022-07-01T06:39:14.220564Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"### Inception Model - Stage 5","metadata":{"slideshow":{"slide_type":"slide"}}},{"cell_type":"code","source":"b5 = nn.Sequential()\nb5.add(Inception(256, (160, 320), (32, 128), 128),\n       Inception(384, (192, 384), (48, 128), 128),\n       nn.GlobalAvgPool2D())\n\nnet = nn.Sequential()\nnet.add(b1, b2, b3, b4, b5, nn.Dense(10))","metadata":{"attributes":{"classes":[],"id":"","n":"6"},"execution":{"iopub.status.busy":"2022-07-01T06:39:14.226952Z","iopub.execute_input":"2022-07-01T06:39:14.229206Z","iopub.status.idle":"2022-07-01T06:39:14.247228Z","shell.execute_reply.started":"2022-07-01T06:39:14.229171Z","shell.execute_reply":"2022-07-01T06:39:14.246269Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"Priming the network (at full size)","metadata":{"slideshow":{"slide_type":"slide"}}},{"cell_type":"code","source":"X = nd.random.uniform(shape=(1, 1, 96, 96))\nnet.initialize()\nfor layer in net:\n    X = layer(X)\n    print(layer.name, 'output shape:\\t', X.shape)","metadata":{"attributes":{"classes":[],"id":"","n":"7"},"execution":{"iopub.status.busy":"2022-07-01T06:39:14.251514Z","iopub.execute_input":"2022-07-01T06:39:14.253730Z","iopub.status.idle":"2022-07-01T06:39:14.499374Z","shell.execute_reply.started":"2022-07-01T06:39:14.253694Z","shell.execute_reply":"2022-07-01T06:39:14.498220Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## Data Acquisition and Training\n\nAs before, we train our model using the Fashion-MNIST dataset. We transform it to $96 \\times 96$ pixel resolution before invoking the training procedure.","metadata":{"slideshow":{"slide_type":"slide"}}},{"cell_type":"code","source":"def get_dataloader_workers(num_workers=4):\n    # 0 means no additional process is used to speed up the reading of data.\n    if sys.platform.startswith('win'):\n        return 0\n    else:\n        return num_workers","metadata":{"execution":{"iopub.status.busy":"2022-07-01T06:39:14.522141Z","iopub.execute_input":"2022-07-01T06:39:14.531090Z","iopub.status.idle":"2022-07-01T06:39:14.544744Z","shell.execute_reply.started":"2022-07-01T06:39:14.531044Z","shell.execute_reply":"2022-07-01T06:39:14.542630Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def load_data_fashion_mnist(batch_size, resize=None):\n    \"\"\"Download the Fashion-MNIST dataset and then load into memory.\"\"\"\n    dataset = gluon.data.vision\n    trans = [dataset.transforms.Resize(resize)] if resize else []\n    trans.append(dataset.transforms.ToTensor())\n    trans = dataset.transforms.Compose(trans)\n    mnist_train = dataset.FashionMNIST(train=True).transform_first(trans)\n    mnist_test = dataset.FashionMNIST(train=False).transform_first(trans)\n    return (gluon.data.DataLoader(mnist_train, batch_size, shuffle=True,\n                                  num_workers=get_dataloader_workers()),\n            gluon.data.DataLoader(mnist_test, batch_size, shuffle=False,\n                                  num_workers=get_dataloader_workers()))","metadata":{"execution":{"iopub.status.busy":"2022-07-01T06:39:14.557837Z","iopub.execute_input":"2022-07-01T06:39:14.563067Z","iopub.status.idle":"2022-07-01T06:39:14.593505Z","shell.execute_reply.started":"2022-07-01T06:39:14.563027Z","shell.execute_reply":"2022-07-01T06:39:14.592583Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def evaluate_accuracy(data_iter, net, ctx):\n    acc_sum, n = nd.array([0], ctx=ctx), 0\n    for X, y in data_iter:\n        # If ctx is the GPU, copy the data to the GPU.\n        X, y = X.as_in_context(ctx), y.as_in_context(ctx).astype('float32')\n        acc_sum += (net(X).argmax(axis=1) == y).sum()\n        n += y.size\n    return acc_sum.asscalar() / n\n\ndef train(net, train_iter, test_iter, batch_size, trainer, ctx,\n              num_epochs):\n    print('training on', ctx)\n    loss = gloss.SoftmaxCrossEntropyLoss()\n    for epoch in range(num_epochs):\n        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n        for X, y in train_iter:\n            X, y = X.as_in_context(ctx), y.as_in_context(ctx)\n            with autograd.record():\n                y_hat = net(X)\n                l = loss(y_hat, y).sum()\n            l.backward()\n            trainer.step(batch_size)\n            y = y.astype('float32')\n            train_l_sum += l.asscalar()\n            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().asscalar()\n            n += y.size\n        test_acc = evaluate_accuracy(test_iter, net, ctx)\n        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, '\n              'time %.1f sec'\n              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc,\n                 time.time() - start))","metadata":{"execution":{"iopub.status.busy":"2022-07-01T06:39:14.597419Z","iopub.execute_input":"2022-07-01T06:39:14.601059Z","iopub.status.idle":"2022-07-01T06:39:14.652065Z","shell.execute_reply.started":"2022-07-01T06:39:14.601022Z","shell.execute_reply":"2022-07-01T06:39:14.648722Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"lr, num_epochs, batch_size, ctx = 0.1, 5, 128, mx.gpu()\nnet.initialize(force_reinit=True, ctx=ctx, init=init.Xavier())\ntrainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': lr})\ntrain_iter, test_iter = load_data_fashion_mnist(batch_size, resize=96)\ntrain(net, train_iter, test_iter, batch_size, trainer, ctx, num_epochs)","metadata":{"attributes":{"classes":[],"id":"","n":"8"},"execution":{"iopub.status.busy":"2022-07-01T06:39:14.653673Z","iopub.execute_input":"2022-07-01T06:39:14.654082Z","iopub.status.idle":"2022-07-01T06:43:34.904670Z","shell.execute_reply.started":"2022-07-01T06:39:14.654038Z","shell.execute_reply":"2022-07-01T06:43:34.903272Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}