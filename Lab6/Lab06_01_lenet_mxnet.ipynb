{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# MNIST, LeNet-5/MXNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import autograd, gluon, init, nd\n",
    "from mxnet.gluon import loss as gloss, nn\n",
    "import time\n",
    "import sys\n",
    "\n",
    "net = nn.Sequential()\n",
    "net.add(nn.Conv2D(channels=6, kernel_size=5, padding=2, activation='sigmoid'),\n",
    "        nn.AvgPool2D(pool_size=2, strides=2),\n",
    "        nn.Conv2D(channels=16, kernel_size=5, activation='sigmoid'),\n",
    "        nn.AvgPool2D(pool_size=2, strides=2),\n",
    "        # Dense will transform the input of the shape (batch size, channel, height, width)\n",
    "        # into the input of the shape (batch size, channel *height * width) automatically\n",
    "        # by default.\n",
    "        nn.Dense(120, activation='sigmoid'),\n",
    "        nn.Dense(84, activation='sigmoid'),\n",
    "        nn.Dense(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Feeding a single observation through the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv0 output shape:\t (1, 6, 28, 28)\n",
      "pool0 output shape:\t (1, 6, 14, 14)\n",
      "conv1 output shape:\t (1, 16, 10, 10)\n",
      "pool1 output shape:\t (1, 16, 5, 5)\n",
      "dense0 output shape:\t (1, 120)\n",
      "dense1 output shape:\t (1, 84)\n",
      "dense2 output shape:\t (1, 10)\n"
     ]
    }
   ],
   "source": [
    "X = nd.random.uniform(shape=(1, 1, 28, 28))\n",
    "net.initialize()\n",
    "for layer in net:\n",
    "    X = layer(X)\n",
    "    print(layer.name, 'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader_workers(num_workers=4):\n",
    "    # 0 means no additional process is used to speed up the reading of data.\n",
    "    if sys.platform.startswith('win'):\n",
    "        return 0\n",
    "    else:\n",
    "        return num_workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_fashion_mnist(batch_size, resize=None):\n",
    "    \"\"\"Download the Fashion-MNIST dataset and then load into memory.\"\"\"\n",
    "    dataset = gluon.data.vision\n",
    "    trans = [dataset.transforms.Resize(resize)] if resize else []\n",
    "    trans.append(dataset.transforms.ToTensor())\n",
    "    trans = dataset.transforms.Compose(trans)\n",
    "    mnist_train = dataset.FashionMNIST(train=True).transform_first(trans)\n",
    "    mnist_test = dataset.FashionMNIST(train=False).transform_first(trans)\n",
    "    return (gluon.data.DataLoader(mnist_train, batch_size, shuffle=True,\n",
    "                                  num_workers=get_dataloader_workers()),\n",
    "            gluon.data.DataLoader(mnist_test, batch_size, shuffle=False,\n",
    "                                  num_workers=get_dataloader_workers()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading /Users/wendywang/.mxnet/datasets/fashion-mnist/train-images-idx3-ubyte.gz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-images-idx3-ubyte.gz...\n",
      "download failed due to SSLError(MaxRetryError(\"HTTPSConnectionPool(host='apache-mxnet.s3-accelerate.dualstack.amazonaws.com', port=443): Max retries exceeded with url: /gluon/dataset/fashion-mnist/train-images-idx3-ubyte.gz (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1129)')))\")), retrying, 4 attempts left\n",
      "Downloading /Users/wendywang/.mxnet/datasets/fashion-mnist/train-images-idx3-ubyte.gz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-images-idx3-ubyte.gz...\n",
      "Downloading /Users/wendywang/.mxnet/datasets/fashion-mnist/train-labels-idx1-ubyte.gz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz...\n",
      "Downloading /Users/wendywang/.mxnet/datasets/fashion-mnist/t10k-images-idx3-ubyte.gz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/t10k-images-idx3-ubyte.gz...\n",
      "Downloading /Users/wendywang/.mxnet/datasets/fashion-mnist/t10k-labels-idx1-ubyte.gz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/t10k-labels-idx1-ubyte.gz...\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "train_iter, test_iter = load_data_fashion_mnist(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[14:31:20] ../src/imperative/./imperative_utils.h:93: GPU support is disabled. Compile MXNet with USE_CUDA=1 to enable GPU support.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "cpu(0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use a GPU if we have it\n",
    "def try_gpu():  \n",
    "    try:\n",
    "        ctx = mx.gpu()\n",
    "        _ = nd.zeros((1,), ctx=ctx)\n",
    "    except mx.base.MXNetError:\n",
    "        ctx = mx.cpu()\n",
    "    return ctx\n",
    "\n",
    "ctx = try_gpu()\n",
    "ctx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net, ctx):\n",
    "    acc_sum, n = nd.array([0], ctx=ctx), 0\n",
    "    for X, y in data_iter:\n",
    "        # If ctx is the GPU, copy the data to the GPU.\n",
    "        X, y = X.as_in_context(ctx), y.as_in_context(ctx).astype('float32')\n",
    "        acc_sum += (net(X).argmax(axis=1) == y).sum()\n",
    "        n += y.size\n",
    "    return acc_sum.asscalar() / n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function has been saved in the d2l package for future use.\n",
    "def train(net, train_iter, test_iter, batch_size, trainer, ctx,\n",
    "              num_epochs):\n",
    "    print('training on', ctx)\n",
    "    loss = gloss.SoftmaxCrossEntropyLoss()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
    "        for X, y in train_iter:\n",
    "            X, y = X.as_in_context(ctx), y.as_in_context(ctx)\n",
    "            with autograd.record():\n",
    "                y_hat = net(X)\n",
    "                l = loss(y_hat, y).sum()\n",
    "            l.backward()\n",
    "            trainer.step(batch_size)\n",
    "            y = y.astype('float32')\n",
    "            train_l_sum += l.asscalar()\n",
    "            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().asscalar()\n",
    "            n += y.size\n",
    "        test_acc = evaluate_accuracy(test_iter, net, ctx)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, '\n",
    "              'time %.1f sec'\n",
    "              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc,\n",
    "                 time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Network initialization and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on cpu(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 2.3191, train acc 0.101, test acc 0.192, time 18.1 sec\n",
      "epoch 2, loss 2.2642, train acc 0.131, test acc 0.465, time 16.6 sec\n",
      "epoch 3, loss 1.1138, train acc 0.552, test acc 0.662, time 16.6 sec\n",
      "epoch 4, loss 0.7981, train acc 0.683, test acc 0.714, time 15.8 sec\n",
      "epoch 5, loss 0.6788, train acc 0.734, test acc 0.767, time 14.9 sec\n",
      "epoch 6, loss 0.6148, train acc 0.760, test acc 0.789, time 15.7 sec\n",
      "epoch 7, loss 0.5627, train acc 0.782, test acc 0.800, time 16.3 sec\n",
      "epoch 8, loss 0.5291, train acc 0.796, test acc 0.811, time 15.8 sec\n",
      "epoch 9, loss 0.5011, train acc 0.808, test acc 0.827, time 14.8 sec\n",
      "epoch 10, loss 0.4729, train acc 0.822, test acc 0.832, time 15.0 sec\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.9, 10\n",
    "net.initialize(force_reinit=True, ctx=ctx, init=init.Xavier())\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': lr})\n",
    "train(net, train_iter, test_iter, batch_size, trainer, ctx, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
